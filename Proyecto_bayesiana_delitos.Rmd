---
title: "Proyecto_bayesiana_final"
author: "Edisson Fabian Tovar Castro"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
# Configuraci√≥n inicial para suprimir mensajes, warnings y salidas innecesarias
knitr::opts_chunk$set(
  message = TRUE,   # Suprime mensajes de las librer√≠as
  warning = FALSE,  # Suprime warnings
  echo = TRUE       # Muestra el c√≥digo en los chunks
    
)

# Configuraci√≥n del locale
suppressWarnings(Sys.setlocale("LC_ALL", "es_ES.UTF-8"))
Sys.setlocale("LC_ALL", "es_ES.UTF-8")

# Cargar librer√≠as necesarias sin mostrar mensajes de inicio
suppressPackageStartupMessages({
  library(gridExtra)
  library(ggplot2)
  library(dplyr)
  library(lubridate)
  library(readr)
  library(tidyr)
  library(brms)
})

```

```{r}
# Ruta del archivo
ruta_archivo <- "/home/fabianvs/Documentos/Rstudio/bayesiana_R/delitos_limpios_bogota.csv"

# Carga el dataset
delitos <- read.csv(ruta_archivo, header = TRUE, sep = ",", encoding = "UTF-8")

# Contenido basico
str(delitos)
```
# 1. Primer modelo
## 1. Introducci√≥n

Breve descripci√≥n del problema: queremos saber si m√°s del 50 % de los atracos se cometen sin armas.

## 2. Hip√≥tesis

- **Hip√≥tesis nula (H0)**  
  La proporci√≥n de delitos sin armas es igual al 50 %.  
  `H0: theta <= 0.5`

- **Hip√≥tesis alternativa (H1)**  
  La proporci√≥n de delitos sin armas supera el 50 %.  
  `H1: theta > 0.5`
## 3. Revisamos la cantidad de delitos sin empleo de armas.

```{r}
set.seed(123)                   # reproducibilidad

## MUESTRA (n = 400 registros/fila)

muestra <- delitos[sample(nrow(delitos), 400), ]

# Total de registros en la muestra
N_m <- nrow(muestra)

# √âxitos: delitos SIN armas
y_no_m <- sum(muestra$ARMAS.MEDIOS == "SIN EMPLEO DE ARMAS")

# Fallos: delitos CON armas (todo lo dem√°s)
y_arm_m <- N_m - y_no_m


## POBLACI√ìN COMPLETA

N_p <- sum(delitos$CANTIDAD)

y_no_p <- sum(delitos$CANTIDAD[
  delitos$ARMAS.MEDIOS == "SIN EMPLEO DE ARMAS"
])

y_arm_p <- N_p - y_no_p


## RESUMEN COMPARATIVO

cat("========== RESUMEN COMPARATIVO: MUESTRA vs POBLACI√ìN ==========\n\n",

    "------ PERSPECTIVA MUESTRAL (n = 400 registros/fila) ------\n",
    "Total registros en la muestra             : ", N_m, "\n",
    "Delitos SIN armas (y_no)                  : ", y_no_m, "\n",
    "Delitos CON armas (y_arm)                 : ", y_arm_m, "\n",
    "Proporci√≥n SIN armas (y_no / N_m)         : ", round(y_no_m / N_m, 3), "\n",
    "Proporci√≥n CON armas (y_arm / N_m)        : ", round(y_arm_m / N_m, 3), "\n\n",

    "------ PERSPECTIVA POBLACIONAL (base completa) ------\n",
    "Total delitos en la base (N_p)            : ", N_p, "\n",
    "Delitos SIN armas en la base (y_no_p)     : ", y_no_p, "\n",
    "Delitos CON armas en la base (y_arm_p)    : ", y_arm_p, "\n",
    "Proporci√≥n SIN armas (y_no_p / N_p)       : ", round(y_no_p / N_p, 3), "\n",
    "Proporci√≥n CON armas (y_arm_p / N_p)      : ", round(y_arm_p / N_p, 3), "\n")
```
## 4. Modelo de verosimilitud

Aqu√≠ modelamos el n√∫mero de delitos sin armas como una distribuci√≥n binomial.

### 1. Modelo binomial

y dado theta sigue una distribuci√≥n binomial:

$$y | theta ~ Binomial(N, theta)$$

### 2. Verosimilitud proporcional

La verosimilitud proporcional (ignorando constantes):

$$L(theta | y) ~ theta^y * (1 - theta)^(N - y)$$

> Fuente: Hoff, P. D. (2009). *A First Course in Bayesian Statistical Methods*. Springer. Cap√≠tulo 2.2.

```{r}
# Valores de N y y en la muestra (para modelo binomial)
# N = n√∫mero de registros (ensayos binomiales)
# y = n√∫mero de √©xitos: delitos sin armas
N <- nrow(muestra)
y <- sum(muestra$ARMAS.MEDIOS == "SIN EMPLEO DE ARMAS")


# Definimos una grilla de valores para Œ∏ (proporci√≥n de delitos sin armas)
# Se usa para evaluar la verosimilitud en el rango (0,1)
theta <- seq(0.001, 0.999, length = 500)

# Calculamos la log-verosimilitud proporcional (sin constantes):
# log L(Œ∏ | y) ‚àù y¬∑log(Œ∏) + (N ‚àí y)¬∑log(1 ‚àí Œ∏)
loglik <- y * log(theta) + (N - y) * log(1 - theta)

# Para evitar problemas num√©ricos (underflow al exponenciar),
# restamos el valor m√°ximo de loglik para que el m√°ximo sea 0
loglik0 <- loglik - max(loglik)

# Exponenciamos para obtener la verosimilitud proporcional (m√°ximo = 1)
lik_proporcional <- exp(loglik0)

# Graficamos la verosimilitud L(Œ∏ | y) en funci√≥n de Œ∏
# Esto muestra qu√© valores de Œ∏ son m√°s compatibles con los datos observados
plot(theta, lik_proporcional, type = "l", lwd = 2, col = "darkorange",
     main = "Verosimilitud Binomial proporcional",
     xlab = "theta", ylab = "L(theta) ~")

```
### 3. Prior Beta(a, b) especificada mediante media y varianza

Para una distribuci√≥n Beta(a, b) se cumple:

**Media:**

$$
\mu = \frac{a}{a + b}
$$

**Varianza:**

$$
\sigma^2 = \frac{a \cdot b}{(a + b)^2 (a + b + 1)}
$$

Si llamamos:

$$
v = a + b
$$

Entonces:

$$
a = \mu \cdot v \quad\quad b = (1 - \mu) \cdot v
$$

Sustituyendo en la varianza se obtiene:

$$
\sigma^2 = \frac{\mu (1 - \mu)}{v + 1}
$$

Despejando \( v \):

$$
v = \frac{\mu (1 - \mu)}{\sigma^2} - 1
$$

Finalmente:

$$
a = \mu \cdot \left( \frac{\mu (1 - \mu)}{\sigma^2} - 1 \right)
\quad\quad
b = (1 - \mu) \cdot \left( \frac{\mu (1 - \mu)}{\sigma^2} - 1 \right)
$$

> **Fuente**: Hoff, P. D. (2009). *A First Course in Bayesian Statistical Methods*. Springer.  
> Ver Cap√≠tulo 2, Secci√≥n 2.3 ‚Äì Prior elicitation for the Beta distribution.

```{r}
## Prior informativa Beta(Œ±, Œ≤)

# Especificamos los momentos deseados para la distribuci√≥n Beta:
mu  <- 0.30   # Media a priori: se espera que Œ∏ ‚âà 0.30 antes de ver los datos
var <- 0.02   # Varianza a priori: mide cu√°nta incertidumbre tenemos sobre Œ∏

# Paso intermedio: calculamos v = Œ± + Œ≤, despejado de la f√≥rmula de la varianza
# F√≥rmula: var = mu * (1 - mu) / (v + 1)  =>  v = mu * (1 - mu) / var - 1
v <- mu * (1 - mu) / var - 1

# Ahora usamos:  Œ± = mu * v , Œ≤ = (1 - mu) * v
alpha <- mu * v     # Calcula Œ± de la Beta(Œ±, Œ≤)
beta  <- (1 - mu) * v  # Calcula Œ≤

# Mostramos los par√°metros redondeados
cat("alpha =", round(alpha, 3), "\n",
    "beta  =", round(beta , 3), "\n")

```
### Graficamos

```{r}
# Visualizaci√≥n de la prior Beta(Œ±, Œ≤)

# Creamos una secuencia de valores posibles de Œ∏ en (0, 1)
theta <- seq(0, 1, length = 500)

# Graficamos la densidad de la distribuci√≥n Beta(Œ±, Œ≤)
# Esto nos muestra c√≥mo luce la creencia previa antes de ver los datos
plot(theta, dbeta(theta, alpha, beta), type = "l",
     main = "Prior Beta",
     xlab = expression(theta),
     ylab = "densidad")
```
### Posterior conjugada: modelo binomial-Beta

Dado un modelo binomial con prior conjugada \( \text{Beta}(\alpha, \beta) \), la distribuci√≥n posterior de \( \theta \) es:

$$
\theta \mid y \sim \text{Beta}(\alpha + y,\ \beta + N - y)
$$

> **Fuentes**:  
> Hoff, P. D. (2009). *A First Course in Bayesian Statistical Methods*. Springer.  
> Cap√≠tulo 2, Secci√≥n 2.2: *Conjugate prior distributions*, p. 33.  
>  
> Correa, J. C., & Barrera, C. J. (2018). *Introducci√≥n a la Estad√≠stica Bayesiana*. ITM.  
> Cap√≠tulo 5.1.1: *Distribuci√≥n binomial con prior Beta*, pp. 33‚Äì34.

```{r}
# 6. Posterior Beta(Œ±*, Œ≤*)

# Actualizamos los par√°metros de la Beta usando la regla de conjugaci√≥n:
#   Œ±* = Œ± + y (√©xitos observados)
#   Œ≤* = Œ≤ + N - y (fracasos observados)
post_alpha <- alpha + y
post_beta  <- beta + N - y

# Mostramos los nuevos par√°metros de la posterior
cat("Posterior Beta(Œ±*, Œ≤*)\n",
    "alpha* =", round(post_alpha, 3), "\n",
    "beta*  =", round(post_beta , 3), "\n")
```

```{r}
# Comparaci√≥n visual: Prior vs Posterior

# Secuencia de valores de Œ∏ en (0, 1)
theta <- seq(0, 1, length = 500)

# Evaluar la densidad de la prior Beta(Œ±, Œ≤)
prior_density <- dbeta(theta, alpha, beta)

# Evaluar la densidad de la posterior Beta(Œ±*, Œ≤*)
posterior_density <- dbeta(theta, post_alpha, post_beta)

# Graficar la prior
plot(theta, prior_density, type = "l", lwd = 2, col = "steelblue",
     ylim = c(0, max(posterior_density) * 1.05),  # ajusta el l√≠mite superior del eje Y
     xlab = expression(theta), ylab = "densidad",
     main = "Distribuciones Prior y Posterior")

# Agregar la posterior sobre el mismo gr√°fico
lines(theta, posterior_density, col = "firebrick", lwd = 2)

# Leyenda del gr√°fico
legend("topright",
       legend = c("Prior", "Posterior"),
       col = c("steelblue", "firebrick"),
       lwd = 2, bty = "n")
```
$$
P(\theta > 0.5 \mid \text{datos})
$$

```{r}
# Probabilidad posterior de que Œ∏ > 0.5

# Calculamos P(Œ∏ > 0.5 | datos) usando la posterior Beta(Œ±*, Œ≤*)
prob_sup_05 <- 1 - pbeta(0.5, post_alpha, post_beta)
 
# Mostramos el resultado
prob_sup_05

```
$$
H_1 : \theta > 0.5
$$

```{r}
# 1) Probabilidad posterior de que Œ∏ > 0.5

# Calcula la probabilidad de que la proporci√≥n Œ∏ de delitos sin armas
# sea mayor que 0.5 bajo la distribuci√≥n posterior Beta(Œ±*, Œ≤*)
prob_sup_05 <- 1 - pbeta(0.5, post_alpha, post_beta)

# Imprime el resultado con 4 cifras decimales
cat("P(Œ∏ > 0.5 | datos) =", round(prob_sup_05, 4), "\n")
```
### 1. Probabilidad posterior
$$
Pr(theta > 0.5 | datos) = 0.1195
$$
Esto significa que, dado el modelo y los datos observados, existe solo una **probabilidad posterior del 11.95%** de que **m√°s de la mitad de los delitos se cometan sin armas**.

**Interpretaci√≥n**: Este valor no es suficientemente alto como para rechazar la hip√≥tesis nula H0: theta <= 0.5.  
Por tanto, **la evidencia respalda H0**, y no se concluye que la mayor√≠a de los delitos ocurran sin armas.


```{r}
## -----Intervalo de m√°xima densidad (HPD) al 95 % -----

# Nivel de significaci√≥n para un intervalo cre√≠ble del 95%
alfa <- 0.05

# Definimos una funci√≥n objetivo que mide el "error" de dos condiciones:
#   1) La masa de probabilidad ‚à´[a,b] p(Œ∏) dŒ∏ debe ser (1 - alfa)
#   2) La densidad en los extremos debe ser la misma: p(a) = p(b)
# La funci√≥n recibe un vector x = c(a, b) y devuelve la suma de cuadrados de ambos errores.
f_hpd <- function(x) {
  # Masa acumulada entre x[1] y x[2]
  masa <- pbeta(x[2], post_alpha, post_beta) -
          pbeta(x[1], post_alpha, post_beta)
  # Densidades en los extremos
  dens_lo <- dbeta(x[1], post_alpha, post_beta)
  dens_hi <- dbeta(x[2], post_alpha, post_beta)
  # Error cuadr√°tico: (masa - (1 - alfa))^2 + (dens_hi - dens_lo)^2
  (masa - (1 - alfa))^2 + (dens_hi - dens_lo)^2
}

# Elegimos como punto inicial para la b√∫squeda un intervalo centrado en la media posterior
media_post <- post_alpha / (post_alpha + post_beta)

# Llamamos a optim() para encontrar [a, b] que minimice f_hpd()
#   c(media_post - 0.1, media_post + 0.1) es la semilla inicial
res <- optim(c(media_post - 0.1, media_post + 0.1), f_hpd)

# Extraemos los l√≠mites √≥ptimos del HPD
hpd_lo <- res$par[1]
hpd_hi <- res$par[2]

# Calculamos la densidad en cada uno de esos extremos
h_lo  <- dbeta(hpd_lo, post_alpha, post_beta)
h_hi  <- dbeta(hpd_hi, post_alpha, post_beta)

# Definimos una ‚Äúaltura com√∫n‚Äù promedio para trazar un segmento horizontal
h_mid <- (h_lo + h_hi) / 2

# Mostramos en consola los valores num√©ricos del intervalo HPD
cat("HPD 95% para Œ∏:\n",
    "  Inferior:", round(hpd_lo, 4), "\n",
    "  Superior:", round(hpd_hi, 4), "\n")

```
### Simulaci√≥n MCMC.

```{r}
set.seed(123)

# Variables espec√≠ficas del modelo binomial
N <- nrow(muestra)
y <- sum(muestra$ARMAS.MEDIOS == "SIN EMPLEO DE ARMAS")

# Fijamos priors expl√≠citos como escalares
alpha_bin <- 2.85
beta_bin  <- 6.65

# Par√°metros de la posterior Beta
shape1 <- alpha_bin + y
shape2 <- beta_bin  + N - y

# MCMC por Random Walk Metropolis
S   <- 10000
sig <- 0.05
theta <- numeric(S)
theta[1] <- 0.5

for (s in 2:S) {
  prev <- theta[s-1]
  prop <- rnorm(1, prev, sig)
  if (prop <= 0 || prop >= 1) {
    theta[s] <- prev
    next
  }
  
  log_num <- as.numeric(dbeta(prop, shape1, shape2, log = TRUE))
  log_den <- as.numeric(dbeta(prev, shape1, shape2, log = TRUE))
  log_r   <- log_num - log_den
  
  if (length(log_r) != 1 || !is.finite(log_r)) log_r <- -Inf
  
  theta[s] <- if (runif(1) < exp(log_r)) prop else prev
}


# 5) Resumen
mean(theta)                     
quantile(theta, c(.025, .5, .975))
```
Cadena MCMC
```{r}
plot(theta, type = "l", col = "blue", lwd = 1,
     main = "Traza de la cadena MCMC",
     xlab = "Iteraci√≥n", ylab = expression(theta))

```


```{r}
# Densidad posterior de la cadena
plot(density(theta), lwd = 2, main = "Posterior de Œ∏", xlab = expression(theta))

# Sombrea el IC al 95 %
polygon(
  c(theta[theta > 0.4208 & theta < 0.5196], 0.4208),
  c(density(theta)$y[theta > 0.4208 & theta < 0.5196], 0),
  col = adjustcolor("skyblue", 0.4), border = NA
)
abline(v = c(0.4208, 0.5196), lty = 2, col = "skyblue4")
abline(v = mean(theta), col = "red", lwd = 2)
legend("topright",
       legend = c("Media posterior", "IC 95 %"),
       col    = c("red", "skyblue4"), lwd = 2, lty = c(1,2))

```

```{r}

# Supongamos que ya tienes post_alpha, post_beta, y h_mid (o h_lo)
altura_objetivo <- h_lo  # o h_hi o h_mid, son iguales

# Funci√≥n para buscar las ra√≠ces (cuando la densidad alcanza la altura del HPD)
f_dens_igual <- function(theta) {
  dbeta(theta, post_alpha, post_beta) - altura_objetivo
}

# B√∫squeda a la izquierda de la moda
cuartil_izq <- uniroot(f_dens_igual, interval = c(0, media_post))$root

# B√∫squeda a la derecha de la moda
cuartil_der <- uniroot(f_dens_igual, interval = c(media_post, 1))$root

# Resultado
cat("Cuartiles con altura igual a la del HPD:\n",
    "Izquierdo:", round(cuartil_izq, 4), "\n",
    "Derecho :", round(cuartil_der, 4), "\n")


# -----------------------------
# Visualizaci√≥n de la posterior Beta y su HPD al 95%
# -----------------------------

# Generamos una grilla de valores de Œ∏ en el intervalo [0, 1]
# Esto nos permitir√° evaluar y graficar la densidad posterior en un rango continuo
theta_vals <- seq(0, 1, length = 500)

# Evaluamos la densidad de la distribuci√≥n posterior Beta(Œ±*, Œ≤*) en cada punto de la grilla
dens_vals  <- dbeta(theta_vals, post_alpha, post_beta)

# Graficamos la curva de densidad posterior
plot(theta_vals, dens_vals, type = "l", lwd = 2, col = "black",
     xlab = expression(theta),               # Etiqueta del eje X (usando notaci√≥n matem√°tica)
     ylab = "Densidad",                      # Etiqueta del eje Y
     main = "Distribuci√≥n posterior Beta y HPD al 95%",  # T√≠tulo del gr√°fico
     ylim = c(0, h_mid * 1.1))               # Limitamos el eje Y ligeramente por encima del HPD

# Dibujamos l√≠neas verticales punteadas en los extremos del intervalo HPD
# Esto marca visualmente los valores de Œ∏ donde empieza y termina el intervalo de m√°xima densidad
abline(v = c(hpd_lo, hpd_hi), col = "red", lty = 2)

# A√±adimos un segmento horizontal a la altura h_mid
# Representa visualmente la "altura constante" del HPD en ambos extremos
segments(x0 = hpd_lo, x1 = hpd_hi,
         y0 = h_mid, y1 = h_mid,
         col = "red", lwd = 2)

# Colocamos puntos rojos sobre los extremos del HPD, en su altura real
# Esto permite verificar visualmente que la altura es (casi) la misma
points(c(hpd_lo, hpd_hi), c(h_lo, h_hi),
       col = "red", pch = 19)

```
```{r}
# ===== Doble panel: izquierda = vista completa, derecha = zoom (alejado) =====
library(ggplot2)
library(gridExtra)

# Reutiliza los objetos que ya calculaste:
# theta_vals, dens_vals, hpd_lo, hpd_hi, h_lo, h_hi, h_mid, cuartil_izq, cuartil_der

df <- data.frame(theta = theta_vals, dens = dens_vals)
pts_rojos  <- data.frame(x = c(hpd_lo, hpd_hi), y = c(h_lo, h_hi))
pts_azules <- data.frame(x = c(cuartil_izq, cuartil_der), y = c(h_mid, h_mid))

capas_comunes <- list(
  geom_line(size = 1.2, colour = "black"),
  geom_vline(xintercept = c(hpd_lo, hpd_hi), colour = "red", linetype = "dashed"),
  geom_segment(aes(x = hpd_lo, xend = hpd_hi, y = h_mid, yend = h_mid),
               inherit.aes = FALSE, colour = "red", linewidth = 1.2),
  geom_point(data = pts_rojos,  aes(x, y), inherit.aes = FALSE, colour = "red",  size = 2),
  geom_vline(xintercept = c(cuartil_izq, cuartil_der), colour = "blue", linetype = "dotted"),
  geom_point(data = pts_azules, aes(x, y), inherit.aes = FALSE, colour = "blue", size = 2),
  labs(x = expression(theta), y = "Densidad"),
  theme_minimal(base_size = 12)
)

# Panel izquierdo (sin zoom)
p_overview <- ggplot(df, aes(theta, dens)) + capas_comunes +
  ggtitle("Vista completa")

# ----------------- Z O O M  A L E J A D O -----------------
w   <- hpd_hi - hpd_lo
mid <- (hpd_lo + hpd_hi) / 2

scale_zoom <- 2.10   # << CAMBIA AQU√ç: 1.10 = 10% m√°s ancho (m√°s alejado)
# (1.00 = igual al HPD, <1 acerca; >1 aleja)

half <- 0.5 * scale_zoom * w
xlim_zoom <- c(max(0, mid - half), min(1, mid + half))

p_zoom <- ggplot(df, aes(theta, dens)) + capas_comunes +
  coord_cartesian(xlim = xlim_zoom, ylim = c(0, h_mid * 1.1)) +
  ggtitle(sprintf("Zoom del (%.0f%%)", 100*scale_zoom))

# Paneles lado a lado (elige el ancho que prefieras)
gridExtra::grid.arrange(p_overview, p_zoom, ncol = 2, widths = c(3, 2))   # 60/40
# gridExtra::grid.arrange(p_overview, p_zoom, ncol = 2, widths = c(1, 1)) # 50/50
# gridExtra::grid.arrange(p_overview, p_zoom, ncol = 2, widths = c(7, 3)) # 70/30




```

```{r}
# -----------------------------
# Calcular cuartiles donde la densidad es igual a la altura del HPD
# -----------------------------

altura_objetivo <- h_lo  # o h_hi o h_mid, son iguales

# Funci√≥n para buscar las ra√≠ces (donde la densidad = altura del HPD)
f_dens_igual <- function(theta) {
  dbeta(theta, post_alpha, post_beta) - altura_objetivo
}

# Buscar ra√≠ces a izquierda y derecha de la media posterior
cuartil_izq <- uniroot(f_dens_igual, interval = c(0, media_post))$root
cuartil_der <- uniroot(f_dens_igual, interval = c(media_post, 1))$root


# -----------------------------
# Visualizaci√≥n con cuartiles sobre la curva (SIN ZOOM)
# -----------------------------

# Graficar la densidad posterior Beta
plot(theta_vals, dens_vals, type = "l", lwd = 2, col = "black",
     xlab = expression(theta),
     ylab = "Densidad",
     main = "Distribuci√≥n posterior Beta y HPD al 95%")

# L√≠nea horizontal del HPD
segments(hpd_lo, h_mid, hpd_hi, h_mid, col = "red", lwd = 2)

# L√≠neas verticales en los extremos del HPD
abline(v = c(hpd_lo, hpd_hi), col = "red", lty = 2)

# Puntos rojos sobre los extremos HPD
points(c(hpd_lo, hpd_hi), c(h_lo, h_hi), col = "red", pch = 19)

# ‚ûï L√≠neas punteadas en los cuartiles donde la densidad es igual a h_mid
abline(v = c(cuartil_izq, cuartil_der), col = "blue", lty = 3)

# ‚ûï Puntos azules sobre los cuartiles
points(c(cuartil_izq, cuartil_der), rep(h_mid, 2), col = "blue", pch = 19)

# Leyenda
legend("topright",
       legend = c("Extremos HPD", "Cuartiles = altura HPD"),
       col    = c("red", "blue"),
       lwd    = 2,
       lty    = c(2, 3),
       pch    = c(19, 19))
```
```{r}
# ===== Doble panel: izquierda = vista completa, derecha = zoom (alejado) =====
library(ggplot2)
library(gridExtra)

# Reutiliza los objetos que ya calculaste:
# theta_vals, dens_vals, hpd_lo, hpd_hi, h_lo, h_hi, h_mid, cuartil_izq, cuartil_der

df <- data.frame(theta = theta_vals, dens = dens_vals)
pts_rojos  <- data.frame(x = c(hpd_lo, hpd_hi), y = c(h_lo, h_hi))
pts_azules <- data.frame(x = c(cuartil_izq, cuartil_der), y = c(h_mid, h_mid))

# --- Estilo base (grilla, tipograf√≠as y caption alineado a la izquierda)
estilo_base <- theme_minimal(base_size = 12) +
  theme(
    panel.grid.major = element_line(colour = "gray85", linewidth = 0.6),
    panel.grid.minor = element_line(colour = "gray92", linewidth = 0.3),
    plot.title       = element_text(face = "bold", hjust = 0.5, size = 18),
    axis.title.x     = element_text(size = 16),
    axis.title.y     = element_text(size = 16),
    plot.caption     = element_text(hjust = 0, size = 10),  # ‚ÄúFuente:‚Äù a la izquierda
    plot.caption.position = "plot"
  )

# ===================== PON ESTE BLOQUE AQU√ç =====================
# (Reemplaza tu definici√≥n anterior de 'capas_comunes' por esta)
capas_comunes <- list(
  geom_line(size = 1.2, colour = "black", alpha = 0.55),      # curva negra m√°s suave
  geom_vline(xintercept = c(hpd_lo, hpd_hi),
             colour = "red", linetype = "dashed", alpha = 0.35),  # (opcional) rojas m√°s suaves
  geom_segment(aes(x = hpd_lo, xend = hpd_hi, y = h_mid, yend = h_mid),
               inherit.aes = FALSE, colour = "red", linewidth = 1.2, alpha = 0.60), # altura roja m√°s suave
  geom_point(data = pts_rojos,  aes(x, y), inherit.aes = FALSE, colour = "red",  size = 2),
  geom_vline(xintercept = c(cuartil_izq, cuartil_der), colour = "red", linetype = "dashed"),
  geom_point(data = pts_azules, aes(x, y), inherit.aes = FALSE, colour = "blue", size = 2),
  labs(x = expression(theta), y = "Densidad", caption = "Fuente: elaboraci√≥n propia"),
  estilo_base
)
# ================================================================

# Panel izquierdo (sin zoom)
p_overview <- ggplot(df, aes(theta, dens)) + capas_comunes +
  ggtitle("Vista completa")

# ----------------- Z O O M  A L E J A D O -----------------
w   <- hpd_hi - hpd_lo
mid <- (hpd_lo + hpd_hi) / 2

scale_zoom <- 2.10   # 1.00 = igual al HPD, <1 acerca; >1 aleja
half <- 0.5 * scale_zoom * w
xlim_zoom <- c(max(0, mid - half), min(1, mid + half))

p_zoom <- ggplot(df, aes(theta, dens)) + capas_comunes +
  coord_cartesian(xlim = xlim_zoom, ylim = c(0, h_mid * 1.1)) +
  ggtitle(sprintf("Zoom del (%.0f%%)", 100*scale_zoom))

# Paneles lado a lado (mantiene proporciones/zoom)
gridExtra::grid.arrange(p_overview, p_zoom, ncol = 2, widths = c(3, 2))   # 60/40
# gridExtra::grid.arrange(p_overview, p_zoom, ncol = 2, widths = c(1, 1)) # 50/50
# gridExtra::grid.arrange(p_overview, p_zoom, ncol = 2, widths = c(7, 3)) # 70/30



```
### 2. Intervalo cre√≠ble al 95%

IC_95% (theta) = [0.4227, 0.5192]

Este intervalo indica que, con un 95% de credibilidad, la proporci√≥n de delitos sin armas se encuentra entre **42.27% y 51.92%**.

**Interpretaci√≥n**: Como el valor 0.5 est√° contenido dentro del intervalo, **no se puede descartar la hip√≥tesis nula**.  
Esto indica que **no hay evidencia suficiente** para afirmar que m√°s del 50% de los delitos se cometen sin armas.



### 5. Conclusi√≥n

Con base en la distribuci√≥n posterior y su intervalo cre√≠ble al 95%, **no se encuentra evidencia estad√≠stica fuerte a favor de la hip√≥tesis alternativa**.  
Por tanto, **no se puede concluir** que la mayor√≠a de los delitos sean cometidos sin armas.


# 2. Segundo modelo. Multinomial Dirichlet
## 1. Introduccion:
Queremos saber:

> ¬øEs la proporci√≥n de delitos cometidos por adultos superior al 65 %?

### Hip√≥tesis bayesiana

- **Hip√≥tesis nula (H0):**  
  La proporci√≥n de v√≠ctimas adultas es igual o menor al 65%.

  $`H0 : theta_adultos <= 0.65`$

- **Hip√≥tesis alternativa (H1):**   
  La proporci√≥n de v√≠ctimas adultas supera el 65%.

  $`H1 : theta_adultos > 0.65`$
```{r}
set.seed(123)
n_m <- 400

# 1) Expandir filas seg√∫n CANTIDAD (cada fila ‚Üí tantas filas como delitos)
delitos_expandidos <- delitos %>% uncount(weights = CANTIDAD)

# 2) Muestreo simple de 400 delitos ‚Äúindividuales‚Äù
muestra2 <- delitos_expandidos %>% slice_sample(n = n_m)

# 3) Ahora reagrupar para volver a sumar CANTIDAD por fila original, si lo necesitas
#    (o directamente trabajar con 'muestra2' como eventos individuales)
y_vec <- muestra2 %>%
  # si necesitas volver a agrupar por edad:
  group_by(AGRUPA.EDAD.PERSONA) %>%
  summarise(y = n(), .groups = "drop")

# 4) Grafico de barras de la muestra ‚Äúreal‚Äù de 400 delitos
ggplot(y_vec, aes(x = AGRUPA.EDAD.PERSONA, y = y)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(
    title = "Conteo de delitos por grupo etario (muestra de 400 delitos)",
    x     = "Grupo etario",
    y     = "N√∫mero de delitos"
  ) +
  theme_minimal()
```

### 2. Modelo y verosimilitud

Supongamos que los conteos por grupo etario siguen una distribuci√≥n **multinomial**:

$$
\mathbf{y} = (y_1, y_2, y_3, y_4) \mid \boldsymbol{\theta} \sim \text{Multinomial}(N, \boldsymbol{\theta}),
$$

donde $\boldsymbol{\theta} = (\theta_1, \theta_2, \theta_3, \theta_4)$ representa las proporciones verdaderas de delitos en cada grupo,  
y $N = \sum_{k=1}^{4} y_k$ es el total de eventos observados.



**Verosimilitud**  
Dada una configuraci√≥n $\boldsymbol{\theta}$ y los datos observados $\mathbf{y}$, la verosimilitud es:

$$
\mathcal{L}(\boldsymbol{\theta} \mid \mathbf{y}) \propto \prod_{k=1}^{4} \theta_k^{y_k}
$$


**Distribuci√≥n a priori: Dirichlet**  
Como prior sobre $\boldsymbol{\theta}$, asumimos una distribuci√≥n Dirichlet con par√°metros  
$\boldsymbol{\alpha} = (\alpha_1, \dots, \alpha_4)$:

$$
p(\boldsymbol{\theta}) \propto \prod_{k=1}^{4} \theta_k^{\alpha_k - 1}
$$



**Posterior no normalizada**  
Aplicando la regla de Bayes (y usando la conjugaci√≥n entre la multinomial y la Dirichlet), la posterior no normalizada es:

$$
p(\boldsymbol{\theta} \mid \mathbf{y}) \propto \mathcal{L}(\boldsymbol{\theta} \mid \mathbf{y}) \cdot p(\boldsymbol{\theta}) 
\propto \prod_{k=1}^{4} \theta_k^{y_k + \alpha_k - 1}
$$

Esta expresi√≥n corresponde a una distribuci√≥n Dirichlet con par√°metros actualizados:  
$\boldsymbol{\alpha}_{\text{posterior}} = \boldsymbol{\alpha} + \mathbf{y}$

```{r}
# === Prior Dirichlet informativa ===

# Definimos las medias esperadas (creencias a priori) para cada grupo etario.
# Estas suman 1, ya que representan una distribuci√≥n de probabilidad categ√≥rica.
mu <- c(
  "NO REPORTADO" = 0.05,
  "adolescentes" = 0.25,
  "adultos"      = 0.60,
  "menores"      = 0.10
)

# Asumimos una varianza com√∫n para todos los grupos (controla la "certeza" del prior)
var_common <- 0.002

# Seleccionamos la media de los adultos (el grupo m√°s frecuente) para calcular Œ±‚ÇÄ
mu_adultos <- mu["adultos"]

# F√≥rmula para calcular Œ±‚ÇÄ a partir de la varianza deseada:
# Œ±‚ÇÄ = (Œº * (1 - Œº) / œÉ¬≤) - 1
alpha0 <- mu_adultos * (1 - mu_adultos) / var_common - 1

# Calculamos el vector de par√°metros Œ± para la distribuci√≥n Dirichlet:
# Œ±·µ¢ = Œº·µ¢ * Œ±‚ÇÄ para cada categor√≠a i
alpha <- mu * alpha0

# Mostramos los valores de Œ± redondeados a 2 decimales
print(round(alpha, 2))

```
### 4. Posterior Dirichlet

Dado que la distribuci√≥n Dirichlet es conjugada con la multinomial,  
la posterior tambi√©n es una Dirichlet, con par√°metros actualizados:

$$
\boldsymbol{\theta} \mid \mathbf{y} \sim \text{Dirichlet}(\alpha_1 + y_1,\ \dots,\ \alpha_4 + y_4)
$$

Esto nos permite actualizar nuestras creencias sobre las proporciones verdaderas de delitos en cada grupo etario.


```{r}
# === Calcular la posterior Dirichlet ===

# Reordenar los valores de alpha para que coincidan con el orden de los grupos en y_vec
alpha <- alpha[y_vec$AGRUPA.EDAD.PERSONA]

# Sumar los conteos observados y los par√°metros de la prior para obtener los par√°metros de la posterior
alpha_post <- setNames(alpha + y_vec$y, y_vec$AGRUPA.EDAD.PERSONA)

# Guardamos la suma total de par√°metros posteriores (Œ±‚ÇÅ + ... + Œ±_k) para usar m√°s adelante
S <- sum(alpha_post)

# -------------------------------------------------------------------------
# GR√ÅFICO COMPARATIVO: VEROSIMILITUD vs PRIOR vs POSTERIOR (Œ∏_adultos)
# -------------------------------------------------------------------------

# === Secuencia de valores de theta para graficar las curvas ===
theta_vals <- seq(1e-4, 1 - 1e-4, length.out = 600)

# Total de delitos observados en la muestra
N <- sum(y_vec$y)

# Conteo observado en el grupo "adultos"
y_adultos <- y_vec$y[y_vec$AGRUPA.EDAD.PERSONA == "adultos"]

# Valor del par√°metro alpha para el grupo "adultos"
alpha_ad <- alpha["adultos"]

# Valor del par√°metro posterior para "adultos"
alpha_post_ad <- alpha_post["adultos"]

# Suma total de los par√°metros posteriores (para posterior beta marginal)
S_post <- sum(alpha_post)

# === Calcular las densidades para graficar ===

# Verosimilitud binomial beta (con prior uniforme Beta(1,1))
lik_vals <- dbeta(theta_vals, y_adultos + 1, N - y_adultos + 1)

# Densidad de la prior marginal para adultos (marginal de la Dirichlet)
prior_vals <- dbeta(theta_vals, alpha_ad, sum(alpha) - alpha_ad)

# Densidad posterior marginal para adultos (tambi√©n beta marginal de Dirichlet)
post_vals <- dbeta(theta_vals, alpha_post_ad, S_post - alpha_post_ad)

# === Funci√≥n para escalar prior y posterior a [0, 1] (para comparaci√≥n visual) ===
scale01 <- function(x) x / max(x)

# === Unir datos en un solo data frame para graficar con ggplot ===
df_plot_mix <- rbind(
  data.frame(theta = theta_vals,
             dens  = lik_vals,           # verosimilitud sin escalar
             tipo  = "Verosimilitud"),
  data.frame(theta = theta_vals,
             dens  = scale01(prior_vals), # prior escalada
             tipo  = "Prior (escalada)"),
  data.frame(theta = theta_vals,
             dens  = scale01(post_vals),  # posterior escalada
             tipo  = "Posterior (escalada)")
)

# === Graficar las tres curvas comparativamente ===
ggplot(df_plot_mix, aes(x = theta, y = dens)) +
  geom_line(color = "black") +
  facet_wrap(~tipo, scales = "free_y") +  # Cada curva en su propio panel con eje y libre
  labs(
    title = expression("Verosimilitud (real), prior y posterior (escaladas) de " * theta[adultos]),
    x     = expression(theta[adultos]),
    y     = "Densidad"
  ) +
  theme_minimal(base_size = 13)

```

```{r}
# Extraer el valor del par√°metro posterior (alpha) correspondiente al grupo "adultos"
a_adultos <- alpha_post["adultos"]

# Calcular la probabilidad posterior de que theta_adultos > 0.65
# Esto corresponde al √°rea bajo la curva Beta(a, b) a la derecha de 0.65
prob_adultos_gt_65 <- 1 - pbeta(0.65, shape1 = a_adultos, shape2 = S - a_adultos)

# Mostrar el resultado con 4 decimales
cat("P(theta_adultos > 0.65 | datos) =", round(prob_adultos_gt_65, 4), "\n")

```
### La probabilidad posterior

\[
P(\theta_{\mathrm{adultos}} > 0.65 \mid \text{datos}) = 0.8262
\]

indica que, seg√∫n el modelo Dirichlet‚ÄìMultinomial y la muestra analizada, hay un **82.62 %** de probabilidad de que la proporci√≥n real de delitos cometidos por adultos supere el 65 %. Este valor denota evidencia moderada a favor de la hip√≥tesis alternativa, aunque no alcanza el umbral del 95 % que solemos exigir para considerarla ‚Äúfuerte‚Äù.


```{r}
# Crear una secuencia de valores entre 0 y 1 para representar posibles valores de theta_adultos
theta_vals <- seq(0, 1, length.out = 500)

# Calcular la densidad de la distribuci√≥n posterior marginal (Beta) para el grupo "adultos"
dens_vals <- dbeta(theta_vals, shape1 = a_adultos, shape2 = S - a_adultos)

# Crear un data frame con los valores de theta y sus densidades correspondientes
df_post <- data.frame(theta = theta_vals, dens = dens_vals)

# Graficar la distribuci√≥n posterior de theta_adultos
ggplot(df_post, aes(x = theta, y = dens)) +
  geom_line(color = "blue", size = 1) +  # curva de densidad en azul
  geom_area(data = subset(df_post, theta > 0.65),  # sombrear regi√≥n theta > 0.65
            aes(x = theta, y = dens),
            fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0.65, linetype = "dashed") +  # l√≠nea vertical punteada en 0.65
  labs(
    title = expression("Distribuci√≥n posterior de " * theta[adultos]),
    x = expression(theta[adultos]),
    y = "Densidad"
  )
```

Como la marginal de cada componente de una Dirichlet es una Beta,  
el intervalo cre√≠ble al 95% para $\theta_{\text{adultos}}$ se obtiene como:


$$
\text{IC}_{95\%}(\theta_{\text{adultos}}) = 
\left[ Q_{0.025},\ Q_{0.975} \right] =
\left[ \text{qbeta}(0.025,\ a,\ S - a),\ \text{qbeta}(0.975,\ a,\ S - a) \right]
$$

donde  $a = \alpha_{\text{adultos}} + y_{\text{adultos}}$


```{r}
# ---------------------------------------------------------
# C√°lculo del intervalo cre√≠ble al 95 % para Œ∏_adultos
# ---------------------------------------------------------

# Como la marginal de cada componente de una Dirichlet es una Beta,
# podemos extraer el intervalo cre√≠ble univariado para Œ∏_adultos
# usando los cuantiles de la distribuci√≥n Beta posterior marginal.

# Los par√°metros de esta Beta son:
#   Œ±* = Œ±_adultos + y_adultos
#   Œ≤* = S - Œ±_adultos - y_adultos
# Donde:
#   - S = suma total de los par√°metros Œ± posteriores
#   - a_adultos = Œ±* para adultos ya calculado

# Obtenemos el intervalo cre√≠ble del 95 % a partir de los percentiles 2.5 % y 97.5 %
IC_adultos <- qbeta(c(0.025, 0.975), shape1 = a_adultos, shape2 = S - a_adultos)

# Mostramos el intervalo en consola, redondeado a 4 decimales
cat("IC 95% para theta_adultos: [",
    round(IC_adultos[1], 4), ",", round(IC_adultos[2], 4), "]\n")


```
### Observaci√≥n

El intervalo cre√≠ble del 95 % para Œ∏<sub>adultos</sub> se encuentra entre **62.83 %** y **70.92 %**, y la probabilidad posterior de que dicha proporci√≥n supere el 65 % es de **82.62 %**.  
Esto sugiere una **tendencia moderada** a favor de que m√°s del 65 % de los delitos fueron cometidos por adultos, aunque la **evidencia no es concluyente** bajo un umbral de alta exigencia como el 95 %.


```{r}
# Graficar la distribuci√≥n posterior de theta_adultos con su intervalo cre√≠ble del 95 %

ggplot(df_post, aes(x = theta, y = dens)) +
  geom_line(color = "blue", size = 1) +  # Curva de densidad posterior en azul

  # Sombrear el √°rea correspondiente al intervalo cre√≠ble [2.5%, 97.5%]
  geom_area(data = subset(df_post, theta > IC_adultos[1] & theta < IC_adultos[2]),
            aes(x = theta, y = dens),
            fill = "green", alpha = 0.3) +

  # L√≠neas verticales en los extremos del intervalo cre√≠ble
  geom_vline(xintercept = IC_adultos, linetype = "dashed", color = "darkgreen") +

  # T√≠tulos y etiquetas de los ejes
  labs(
    title = expression("Intervalo cre√≠ble al 95% para " * theta[adultos]),
    x = expression(theta[adultos]),
    y = "Densidad"
  )

```
### Observaci√≥n

El intervalo cre√≠ble al 95 % para Œ∏<sub>adultos</sub>, sombreado en verde en la figura, va aproximadamente de **0.6283** a **0.7092**. Esto significa que, dadas la muestra observada y la prior especificada, hay un 95 % de probabilidad de que la proporci√≥n verdadera de delitos cometidos por adultos se sit√∫e en ese rango. Como todo el intervalo est√° por encima de 0.65, refuerza la evidencia a favor de la hip√≥tesis alternativa
\[
H_1:\ \theta_{\text{adultos}} > 0.65.
\]

```{r}
# Decisi√≥n bayesiana basada en dos criterios:
# 1) Probabilidad posterior > 0.95
# 2) El l√≠mite inferior del intervalo cre√≠ble tambi√©n es > 0.65

# Validaci√≥n de que los valores no son NA (por seguridad)
if (!is.na(prob_adultos_gt_65) &&
    !is.na(IC_adultos[1]) &&
    prob_adultos_gt_65 > 0.95 &&         # Criterio 1: alta probabilidad posterior
    IC_adultos[1] > 0.65) {              # Criterio 2: el IC est√° completamente por encima de 0.65

  mensaje <- "Evidencia fuerte a favor de H1: la proporci√≥n de v√≠ctimas adultas es mayor al 65%."

} else {

  mensaje <- "No hay evidencia suficiente para concluir que las v√≠ctimas adultas superan el 65%."

}

# Mostrar mensaje de decisi√≥n
cat(mensaje, "\n")
```
### Conclusi√≥n final

No se cumple el criterio de decisi√≥n bayesiana para considerar **evidencia fuerte** a favor de la hip√≥tesis alternativa.  
Aunque la probabilidad posterior de que la proporci√≥n de delitos cometidos por adultos supere el 65% es **82.62%**,  
el **intervalo cre√≠ble del 95%** no se encuentra completamente por encima de 0.65.  

Por tanto, **no hay evidencia suficiente para afirmar que m√°s del 65% de los delitos fueron cometidos por adultos**,  
seg√∫n los datos analizados y el modelo Dirichlet‚ÄìMultinomial especificado.

```{r}
# ----------------------------
# PAR√ÅMETROS DEL MODELO
# ----------------------------

# Conteos por grupo etario (ejemplo real del documento)
y <- c(
  adultos      = sum(muestra$AGRUPA.EDAD.PERSONA == "adultos"),
  adolescentes = sum(muestra$AGRUPA.EDAD.PERSONA == "adolescentes"),
  menores      = sum(muestra$AGRUPA.EDAD.PERSONA == "menores"),
  noreportado  = sum(muestra$AGRUPA.EDAD.PERSONA == "No reportado")
)

# Prior Dirichlet plana
alpha <- rep(1, 4)

# ----------------------------
# GIBBS SAMPLER PARA DIRICHLET
# ----------------------------
S <- 10000  # iteraciones
theta_chain <- matrix(NA, nrow = S, ncol = 4)
colnames(theta_chain) <- names(y)

for (s in 1:S) {
  g <- rgamma(4, shape = alpha + y, rate = 1)
  theta_chain[s, ] <- g / sum(g)
}

# ----------------------------
# RESULTADOS NUM√âRICOS
# ----------------------------
theta_mean <- colMeans(theta_chain)
theta_HPD <- apply(theta_chain, 2, quantile, probs = c(0.025, 0.975))

# Mostramos resultados
theta_mean
theta_HPD

# ----------------------------
# GR√ÅFICO DE TRAZA PARA ùúÉ_adultos
# ----------------------------
plot(theta_chain[, "adultos"], type = "l", col = "blue",
     ylab = expression(theta[adultos]), xlab = "Iteraci√≥n",
     main = "Traza de la cadena MCMC para Œ∏ adultos")

```

```{r}
# ----------------------------------------------------------
# 1. Conteos observados
# ----------------------------------------------------------
y <- c(
  "NO REPORTADO" = 99,
  "adolescentes" = 15,
  "adultos"      = 276,
  "menores"      = 10
)

# ----------------------------------------------------------
# 2. Prior Dirichlet informativa (usa tus Œ± ya calculadas)
#    ‚Äî aqu√≠ coloco las que obtuviste con la varianza 0.002 ‚Äî
# ----------------------------------------------------------
alpha <- c(
  "NO REPORTADO" = 2.60,   # 0.05 * Œ±‚ÇÄ  (Œ±‚ÇÄ ‚âà 51.98)
  "adolescentes" = 13.00,  # 0.25 * Œ±‚ÇÄ
  "adultos"      = 31.19,  # 0.60 * Œ±‚ÇÄ
  "menores"      = 5.20    # 0.10 * Œ±‚ÇÄ
)
# comprueba que los nombres coinciden
stopifnot(all(names(y) == names(alpha)))

# ----------------------------------------------------------
# 3. Gibbs sampler (10 000 iteraciones)
# ----------------------------------------------------------
set.seed(123)
S <- 10000
theta_chain <- matrix(NA, nrow = S, ncol = 4,
                      dimnames = list(NULL, names(y)))

for (s in 1:S) {
  g <- rgamma(4, shape = alpha + y, rate = 1)
  theta_chain[s, ] <- g / sum(g)
}

# ----------------------------------------------------------
# 4. Resultados num√©ricos
# ----------------------------------------------------------
theta_mean <- colMeans(theta_chain)
theta_HPD  <- t(apply(theta_chain, 2, quantile,
                      probs = c(0.025, 0.975)))

print(round(theta_mean, 4))
print(round(theta_HPD, 4))

# ----------------------------------------------------------
# 5. Traza para Œ∏_adultos
# ----------------------------------------------------------
plot(theta_chain[, "adultos"], type = "l", col = "blue",
     ylab = expression(theta[adultos]), xlab = "Iteraci√≥n",
     main = expression("Traza de la cadena MCMC para " * theta[adultos]))


```

```{r}

```
# 3. Bogota vs Cali
## 1. Bogota - Planteamiento de la hipotesis

### 1. Pregunta concreta  
¬øLa tasa anual de delitos en Bogota ha aumentado entre 2010 y 2019?

Sea $Y_{Bog,t}$ el conteo de delitos en el a√±o $t$ y  
$$\lambda_{Bog,t} = \operatorname{E}[Y_{Bog,t}]$$.

Modelamos  
$$
Y_{Bog,t} \mid \lambda_{Bog,t} \sim \text{Poisson}(\lambda_{Bog,t}), \qquad  
\log \lambda_{Bog,t} = \alpha_{Bog} + \beta_{Bog} \cdot (t - 2010).
$$

### 2.Hip√≥tesis

$$
\begin{aligned}
\mathbf{H}_0 &: \quad \beta_{\text{Bog}} \le 0
               &&\Longleftrightarrow&&
               \lambda_{\text{Bog},2019} \le \lambda_{\text{Bog},2010} \\[4pt]
\mathbf{H}_1 &: \quad \beta_{\text{Bog}} > 0
               &&\Longleftrightarrow&&
               \lambda_{\text{Bog},2019} > \lambda_{\text{Bog},2010}
\end{aligned}
$$

La decisi√≥n se tomar√° con la probabilidad posterior

$$
P\!\bigl(\beta_{\text{Bog}} > 0 \,\bigm|\, \mathbf y\bigr)
$$

o verificando si el intervalo cre√≠ble (95%) del cociente

$$
\frac{\lambda_{\text{Bog},2019}}{\lambda_{\text{Bog},2010}}
$$

excluye el valor 1


### 3.Preprocesamiento

```{r}
bog_path <- "/home/fabian/Documentos/bayesiana_R/delitos_limpios_bogota.csv"
# Carga el dataset
delitos_bogo <- read.csv(bog_path, header = TRUE, sep = ",", encoding = "UTF-8")
# üîé Eliminaci√≥n de registros con fecha faltante
delitos_bogo <- delitos_bogo %>%
  filter(!is.na(FECHA.HECHO))
# Contenido basico
str(delitos_bogo)
```



```{r}
## ---------------------------------------------------------------
##  SEGUNDO MODELO CON MUESTRA (Poisson‚Äëregresi√≥n con Œ≤)
## ---------------------------------------------------------------
set.seed(123)         # reproducibilidad
n_m <- 400            # tama√±o de la muestra (puedes variar)

# --- Muestra aleatoria ---------------------------------------
muestra3 <- delitos_bogo[sample(nrow(delitos_bogo), n_m), ]

# --- Limpieza de categor√≠a vac√≠a -----------------------------
muestra3 <- muestra3 %>%
  mutate(year = year(as.Date(FECHA.HECHO)))
```
**Objetivo**

Queremos obtener \( y_t \), el n√∫mero total de delitos registrados en **Bogot√°**, dentro de la muestra, para cada a√±o \( t \in \{2010, \ldots, 2019\} \).  
Estos conteos actuar√°n como la **estad√≠stica suficiente** para ajustar el modelo de regresi√≥n Poisson con tendencia temporal.

**Notaci√≥n**

$$
y_t = \sum_{i=1}^{n_t} \mathrm{CANTIDAD}_i \qquad \text{(en la muestra)}
$$


```{r}
bogo_yr_m <- muestra3 %>%
  group_by(year) %>%
  summarise(y = sum(CANTIDAD), .groups = "drop")
head(bogo_yr_m)
```
```{r}
str(bogo_yr_m)
```

### PASO 4: Verosimilitud ‚Äì Poisson

#### Modelo estad√≠stico

Suponemos que el n√∫mero de delitos \( y_t \) en el a√±o \( t \) sigue una distribuci√≥n Poisson con media \( \lambda_t \):

$$
y_t \mid \lambda_t \sim \operatorname{Poisson}(\lambda_t)
$$

Como modelamos una **tendencia temporal**, la media se expresa mediante una relaci√≥n log-lineal:

$$
\log \lambda_t = \alpha + \beta (t - 2010)
$$


```{r}
# --- 4. Ajuste del modelo Poisson con pendiente Œ≤ ---------------
#   y_t ~ Poisson(exp(alpha + beta*(year-2010)))

prior_list <- c(
  prior(normal(0, 10), class = Intercept),   # Œ±
  prior(normal(0, 10), class = b)            # Œ≤
)

bogo_brms <- brm(
  formula = y ~ 1 + I(year - 2010),          # Œ± + Œ≤*(t-2010)
  family  = poisson(link = "log"),
  data    = bogo_yr_m,
  prior   = prior_list,
  chains  = 4, iter = 4000, seed = 123,
  refresh = 0                                # menos salida en pantalla
)
```


### 5. Inferencia posterior y comparaci√≥n temporal

Una vez ajustado el modelo de regresi√≥n Poisson con enlace logar√≠tmico mediante inferencia bayesiana (usando MCMC con `brms`), el siguiente paso es **interpretar los par√°metros posteriores**, en particular:

- La **pendiente** \( \beta \), que representa el cambio promedio anual en la tasa logar√≠tmica de delitos.
- Las tasas \( \lambda_t = \exp(\alpha + \beta \cdot (t - 2010)) \), en a√±os espec√≠ficos (como 2010 y 2019).

Desde una perspectiva bayesiana, la inferencia se basa en el an√°lisis de **distribuciones posteriores completas**, no en estimaciones puntuales ni valores-*p* cl√°sicos. Por ello:

- Se estima la **probabilidad posterior** de que \( \beta > 0 \), lo que responde directamente a la hip√≥tesis alternativa.
- Se simulan las tasas \( \lambda_{2010} \) y \( \lambda_{2019} \) a partir de las muestras posteriores, lo que permite:

  - Calcular \( P(\lambda_{2019} > \lambda_{2010}) \)
  - Obtener el intervalo cre√≠ble del 95% para el **cociente**:

    $$
    \frac{\lambda_{2019}}{\lambda_{2010}}
    $$

Este enfoque sigue los principios del an√°lisis bayesiano descritos por [Gelman et al. (2013)](https://www.stat.columbia.edu/~gelman/book/), quienes promueven el uso de simulaciones posteriores para realizar inferencias sobre transformaciones de par√°metros, como diferencias, razones o probabilidades.

En t√©rminos pr√°cticos, **el objetivo de esta secci√≥n es verificar si los datos respaldan una tendencia creciente en la tasa de delitos en Bogot√° entre 2010 y 2019**.


```{r}
# --- 5. Probabilidad posterior de Œ≤>0 ---------------------------
post_draws <- as_draws_df(bogo_brms)

prob_beta_gt0 <- mean(post_draws$b_IyearM2010 > 0)

cat("P(Œ≤ > 0 | muestra) ‚âà", round(prob_beta_gt0, 4), "\n")
```



### 6. Comparaci√≥n de tasas esperadas: \( \lambda_{2019} \) vs. \( \lambda_{2010} \)

Una vez ajustado el modelo con `brms`, utilizamos las muestras posteriores obtenidas mediante MCMC para simular y comparar las tasas esperadas de delitos 
en los a√±os extremos: **2010** y **2019**.

#### Fundamento

Dado que el modelo asume:

$$
\log \lambda_t = \alpha + \beta \cdot (t - 2010)
\quad \Rightarrow \quad
\lambda_t = \exp\bigl(\alpha + \beta \cdot (t - 2010)\bigr),
$$

para los a√±os espec√≠ficos:

- \( \lambda_{2010} = \exp(\alpha) \)  
- \( \lambda_{2019} = \exp(\alpha + 9\beta) \)

Simulando estas tasas para cada muestra de la posterior, podemos:

1. Estimar directamente la probabilidad  
   \( P(\lambda_{2019} > \lambda_{2010}) \),  
   sin recurrir a pruebas frecuentistas.

2. Obtener el **intervalo cre√≠ble del 95%** del cociente:

   $$
   \frac{\lambda_{2019}}{\lambda_{2010}},
   $$

   lo cual indica en qu√© magnitud habr√≠a aumentado (o disminuido) la tasa.

Este enfoque es coherente con la pr√°ctica bayesiana recomendada por *Gelman et al.* (2013, Cap.3.4), donde la comparaci√≥n de cantidades derivadas,
como diferencias, cocientes o probabilidades entre par√°metros, se realiza mediante simulaci√≥n directa desde la distribuci√≥n posterior.


```{r}
# --- 6. Simular Œª_2010 y Œª_2019 ---------------------------------
lambda_2010 <- exp(post_draws$b_Intercept)                # Œ±  (t=2010)
lambda_2019 <- exp(post_draws$b_Intercept +
                   post_draws$b_IyearM2010 * 9)           # Œ±+Œ≤*9

prob_lambda_ratio <- mean(lambda_2019 > lambda_2010)

ratio_Q <- quantile(lambda_2019 / lambda_2010,
                    probs = c(0.025, 0.5, 0.975))

cat("P(Œª_2019 > Œª_2010) ‚âà", round(prob_lambda_ratio, 4), "\n",
    "IC95% de la raz√≥n Œª_2019 / Œª_2010:",
    paste(round(ratio_Q, 3), collapse = " ‚Äì "), "\n")

```
####**Observaci√≥n**

La probabilidad posterior  
\[
P(\theta_{\mathrm{adultos}} > 0.65 \mid \text{datos}) \approx 0.8262
\]  
indica que hay un **82.62 %** de masa de probabilidad acumulada por encima del umbral 0.65, con un valor medio cercano a la zona central de la distribuci√≥n. Adem√°s, el intervalo cre√≠ble al 95 % para \(\theta_{\mathrm{adultos}}\),  
\[
[0.6283,\ 0.7092],
\]  
toca ligeramente valores por debajo de 0.65 en su extremo inferior, lo cual sugiere una **evidencia moderada** a favor de la hip√≥tesis alternativa \(H_1: \theta_{\mathrm{adultos}}>0.65\), pero sin alcanzar el rigor de un 95 % de certeza completa.


### **Paso 7: Visualizaci√≥n ‚Äì evoluci√≥n de la tasa \( \lambda_t \)**

#### **Objetivo**

Representar gr√°ficamente, para cada a√±o \( t \in \{2010, \dots, 2019\} \):

- La **media posterior** de la tasa esperada \( \lambda_t = \mathbb{E}[Y_t] \)
- Un **intervalo cre√≠ble del 95%** para cada \( \lambda_t \), derivado de las simulaciones posteriores del modelo de regresi√≥n log-lineal:

  $$
  \lambda_t = \exp\bigl(\alpha + \beta \cdot (t - 2010)\bigr)
  $$

Este paso permite **visualizar la tendencia temporal** en la tasa de delitos, e interpretar de forma intuitiva si existe un aumento consistente, 
as√≠ como la **incertidumbre asociada** en cada punto temporal.

La construcci√≥n de estas curvas se basa en las muestras MCMC de los par√°metros \( \alpha \) y \( \beta \), a partir de las cuales se generan 
distribuciones completas de \( \lambda_t \) para cada a√±o.

Este enfoque es coherente con la pr√°ctica bayesiana recomendada por *Gelman et al.* (2013, Cap. 3.4), donde la comparaci√≥n de cantidades derivadas,
como diferencias, cocientes o probabilidades entre par√°metros, se realiza mediante simulaci√≥n directa desde la distribuci√≥n posterior.

```{r}
# --- 7. Evoluci√≥n de Œª_t en el tiempo ---------------------------

# Secuencia de a√±os
years <- sort(unique(bogo_yr_m$year))

# Para cada a√±o, computamos Œª_t = exp(Œ± + Œ≤*(t - 2010)) en cada muestra
lambda_mat <- sapply(years, function(t) {
  exp(post_draws$b_Intercept + post_draws$b_IyearM2010 * (t - 2010))
})

# Convertimos en data frame resumen (promedios e ICs por a√±o)
lambda_df <- data.frame(
  year = years,
  mean = apply(lambda_mat, 2, mean),
  q025 = apply(lambda_mat, 2, quantile, probs = 0.025),
  q975 = apply(lambda_mat, 2, quantile, probs = 0.975)
)

# Graficar evoluci√≥n
ggplot(lambda_df, aes(x = year, y = mean)) +
  geom_ribbon(aes(ymin = q025, ymax = q975), fill = "skyblue", alpha = 0.4) +
  geom_line(color = "blue", size = 1) +
  geom_point(size = 2) +
  labs(
    title = "Evoluci√≥n de la tasa esperada de delitos en Bogot√°",
    subtitle = "Media posterior y intervalo cre√≠ble del 95%",
    x = "A√±o", y = expression(lambda[t])
  ) +
  theme_minimal()


```
#### **Interpretaci√≥n de la gr√°fica**

La siguiente gr√°fica muestra la **evoluci√≥n de la tasa esperada de delitos anuales en Bogot√°** (\( \lambda_t \)) durante el periodo 2010‚Äì2019, 
basada en el modelo de regresi√≥n Poisson ajustado mediante inferencia bayesiana.

- **L√≠nea azul gruesa**: Representa la **media posterior** de \( \lambda_t \) para cada a√±o, es decir, el valor esperado del n√∫mero de delitos 
seg√∫n el modelo y los datos observados.

- **Banda azul clara**: Corresponde al **intervalo cre√≠ble del 95%**, calculado a partir de los percentiles 2.5% y 97.5% de las simulaciones 
posteriores de \( \lambda_t \). Esta banda refleja la **incertidumbre** sobre la tasa verdadera en cada a√±o.

- **Puntos negros**: Se√±alan los valores medios estimados, resaltando el **comportamiento a√±o a a√±o** de la tasa.
#### **Observaci√≥n**

La forma creciente y progresiva de la curva de \( \lambda_t \), junto con intervalos cre√≠bles cada vez m√°s amplios hacia los √∫ltimos a√±os, 
sugiere una evoluci√≥n ascendente en la tasa esperada de delitos durante el periodo 2010‚Äì2019. Esta representaci√≥n visual complementa 
la evidencia num√©rica obtenida en pasos anteriores y proporciona una interpretaci√≥n intuitiva de la tendencia modelada en el contexto 
de la inferencia bayesiana.

## 8. Decisi√≥n

#### Regla de decisi√≥n

Se rechaza la hip√≥tesis nula \( \mathbf{H}_0 \) si **al menos uno** de los siguientes criterios se cumple ‚Äîambos derivados directamente de la distribuci√≥n posterior:

1. \( P(\beta > 0 \mid \text{datos}) > 0.95 \)
2. \( P(\lambda_{2019} > \lambda_{2010} \mid \text{datos}) > 0.95 \)

> El umbral de 0.95 es un est√°ndar com√∫nmente aceptado para considerar que existe **evidencia fuerte** a favor de la hip√≥tesis alternativa 
en an√°lisis bayesiano (Gelman et al., 2013).


```{r}
# === 8. Decisi√≥n m√°s informativa =====================================

cat("Decisi√≥n inferencial\n")
cat(sprintf("P(Œ≤ > 0 | datos)        = %.4f\n", prob_beta_gt0))
cat(sprintf("P(Œª_2019 > Œª_2010)      = %.4f\n", prob_lambda_ratio))
cat(sprintf("IC 95%% de Œª_2019 / Œª_2010 = [%.3f, %.3f]\n",
            ratio_Q[1], ratio_Q[3]))

if (prob_beta_gt0 > 0.95 || prob_lambda_ratio > 0.95) {
  cat("\nConclusi√≥n: hay *evidencia fuerte* de que la tasa de delitos en Bogot√° ha aumentado entre 2010 y 2019.\n")
} else {
  cat("\nConclusi√≥n: no hay evidencia suficiente para afirmar que la tasa ha aumentado.\n")
}

```



## 9. Chequeo predictivo posterior

### Fundamento

El **chequeo predictivo posterior** (*posterior predictive check*, PPC) es una herramienta fundamental del an√°lisis bayesiano. Su objetivo es:

> Comparar los datos observados con datos simulados a partir del modelo ajustado,  
> para evaluar si este reproduce adecuadamente las caracter√≠sticas esenciales de los datos.

Este enfoque se basa en simular observaciones futuras \( y^{\text{rep}} \sim p(y \mid \theta) \), utilizando par√°metros \( \theta \) 
extra√≠dos de la distribuci√≥n posterior, y luego comparar estas simulaciones con los datos reales.

Se trata de un principio clave defendido por *Gelman et al.* (2013, Cap.6.3), quienes afirman:

> *‚ÄúModel checking and model expansion are key steps in Bayesian data analysis.‚Äù*

### ¬øQu√© se chequea?

1. Que los conteos de delitos generados por el modelo (Poisson) sean coherentes con los observados.
2. Que el modelo log-lineal en el tiempo sea capaz de reproducir la evoluci√≥n anual de los delitos.


### Parte 1: Chequeo global (con `pp_check()`)

El siguiente gr√°fico muestra la distribuci√≥n de los conteos observados frente a los conteos simulados, mediante histogramas 
generados con la funci√≥n `pp_check()` de `brms`.  

Este chequeo visual permite evaluar si el modelo Poisson ajustado es razonable para los datos observados.


```{r}
# Chequeo global con 200 r√©plicas simuladas
pp_check(bogo_brms, nsamples = 200) +
  ggtitle("Chequeo predictivo posterior (PPC)  Bogot√°",
          subtitle = "¬øEl modelo puede generar datos similares a los observados?")
```
####**Observaci√≥n sobre el PPC de Bogot√°**

El gr√°fico superpone la densidad de los datos observados (l√≠nea azul oscura) con 200 r√©plicas simuladas desde la posterior (l√≠neas azul claro):

* La mayor parte de las curvas simuladas se agrupan en un modo principal ‚Äîaprox. entre 50 y 150 delitos‚Äî y reproducen razonablemente la forma decreciente de la cola intermedia.  
* Sin embargo, el histograma observado exhibe **un segundo ‚Äúbulto‚Äù en el extremo derecho** (alrededor de 450 delitos) que **casi ninguna simulaci√≥n reproduce**.  
* Esta discrepancia sugiere que el modelo Poisson log‚Äëlineal **subestima la probabilidad de a√±os con conteos excepcionalmente altos**; dicho de otro modo, la cola derecha de la distribuci√≥n real es m√°s pesada de lo que asume el modelo.  
* Podr√≠a ser indicio de **sobre‚Äëdispersi√≥n** o de un **cambio estructural** (por ejemplo, un a√±o at√≠pico o un fen√≥meno no capturado por la tendencia lineal).  

En conjunto, el PPC indica que, si bien el modelo describe bien la din√°mica general, **no capta plenamente los eventos extremos**, por lo que convendr√≠a explorar extensiones (p.ej. una distribuci√≥n negativabinomial o un componente de cambio de nivel).


### Parte 2: Chequeo por a√±o (intervalos predictivos)

Muestra si el modelo reproduce adecuadamente los conteos por a√±o, junto con intervalos creibles para cada $y_t$.

```{r}
# Chequeo por intervalo a√±o a a√±o
pp_check(bogo_brms, type = "intervals") +
  ggtitle("Chequeo PPC por a√±o Bogot√°",
          subtitle = "Intervalos predictivos para cada a√±o comparados con observaciones")
```
####**Observaci√≥n sobre el PPC ‚Äúintervals‚Äù a√±o a a√±o (Bogot√°)**

El gr√°fico compara, para cada punto temporal (a√±os 2010‚Äë2019), los conteos reales (puntos azul oscuro) con los **intervalos predictivos del 90‚ÄØ%** derivados de la posterior (puntos y barras azul claro).

* **Ajuste razonable en los primeros a√±os ‚âà(2010‚Äë2014).**  
  Los datos observados caen cerca del centro de los intervalos simulados, indicando que el modelo reproduce bien los niveles iniciales.

* **Tendencia capturada pero con ligera sub‚Äëestimaci√≥n intermedia ‚âà(2015‚Äë2017).**  
  Los valores reales se sit√∫an en la parte alta de los intervalos, sugiriendo que el crecimiento real supera levemente la pendiente estimada.

* **Fallo claro en 2018‚Äë2019.**  
  El conteo real de 2018 queda por encima del l√≠mite superior del 90% P.I., y 2019 es a√∫n m√°s extremo, fuera del rango de casi todas las simulaciones.  
  Esto confirma la **cola derecha pesada** detectada en el PPC global: el modelo Poisson log‚Äëlineal subestima eventos de alta criminalidad al final de la serie.

En resumen, el modelo describe bien los a√±os iniciales y la tendencia general, pero resulta **demasiado optimista (o r√≠gido) para los picos recientes**, apuntando de nuevo a la necesidad de modelar sobre‚Äëdispersi√≥n o incorporar un t√©rmino de cambio estructural.

```{r}
# ----------------------------------------------------------
# 0. Datos (ya calculados en tu flujo)
# ----------------------------------------------------------
# bogo_yr_m: data.frame con columnas year (2010‚Äë2019) y y (conteo)
years <- bogo_yr_m$year
y     <- bogo_yr_m$y
stopifnot(length(years) == length(y))   # seguridad

# ----------------------------------------------------------
# 1. Priors d√©biles: Œ±, Œ≤ ~ Normal(0, 10^2)
# ----------------------------------------------------------
prior_sd <- 10

# ----------------------------------------------------------
# 2. Funci√≥n de log‚Äëposterior
# ----------------------------------------------------------
log_post <- function(alpha, beta) {
  lambda <- exp(alpha + beta * (years - 2010))
  sum(dpois(y, lambda, log = TRUE)) +
    dnorm(alpha, 0, prior_sd, log = TRUE) +
    dnorm(beta,  0, prior_sd, log = TRUE)
}

# ----------------------------------------------------------
# 3. Metropolis‚Äëwithin‚ÄëGibbs
# ----------------------------------------------------------
set.seed(123)
S <- 20000            # iteraciones totales
burn <- 5000          # descartadas como 'burn‚Äëin'

alpha <- beta <- numeric(S)
alpha[1] <- 0         # punto de arranque
beta[1]  <- 0
sd_prop_alpha <- 0.30 # varianzas de propuesta
sd_prop_beta  <- 0.05

for (s in 2:S) {
  # ---- actualizar Œ±
  a_prop <- rnorm(1, alpha[s-1], sd_prop_alpha)
  log_r  <- log_post(a_prop, beta[s-1]) - log_post(alpha[s-1], beta[s-1])
  alpha[s] <- if (log(runif(1)) < log_r) a_prop else alpha[s-1]

  # ---- actualizar Œ≤
  b_prop <- rnorm(1, beta[s-1], sd_prop_beta)
  log_r  <- log_post(alpha[s], b_prop) - log_post(alpha[s], beta[s-1])
  beta[s] <- if (log(runif(1)) < log_r) b_prop else beta[s-1]
}

# ----------------------------------------------------------
# 4. Resumen posterior y diagn√≥sticos
# ----------------------------------------------------------
alpha_post <- alpha[-(1:burn)]
beta_post  <- beta[-(1:burn)]

c(
  mean_alpha = mean(alpha_post),
  mean_beta  = mean(beta_post),
  prob_beta_gt0 = mean(beta_post > 0)
)

# ---- tasas para 2010 y 2019
lambda_2010 <- exp(alpha_post)                    # t = 2010 ‚áí Œ≤*(0)
lambda_2019 <- exp(alpha_post + beta_post * 9)    # t = 2019 ‚áí Œ≤*(9)

prob_ratio_gt1 <- mean(lambda_2019 > lambda_2010)
ratio_hpd      <- quantile(lambda_2019 / lambda_2010, c(.025, .5, .975))

# ----------------------------------------------------------
# 5. Graficas de convergencia (ejemplo: traza de Œ≤)
# ----------------------------------------------------------
par(mfrow = c(1,2))
plot(beta_post, type = "l", col = "blue",
     main = expression("Trace de "*beta),
     ylab = expression(beta), xlab = "Iteraci√≥n")
acf(beta_post, main = expression("ACF de "*beta))

```
## 10. Conclusiones

A partir del an√°lisis bayesiano realizado, se obtuvieron los siguientes resultados clave:

- \( P(\lambda_{2019} > \lambda_{2010}) \approx 1 \)
- Intervalo cre√≠ble del 95% para la raz√≥n \( \lambda_{2019} / \lambda_{2010} \):  
  \( 15.948 \) ‚Äì \( 19.820 \) ‚Äì \( 24.852 \)



### Decisi√≥n inferencial

Los criterios definidos previamente para rechazar la hip√≥tesis nula se cumplen claramente:

- \( P(\beta > 0 \mid \text{datos}) = 1.0000 \)
- \( P(\lambda_{2019} > \lambda_{2010} \mid \text{datos}) = 1.0000 \)
- Intervalo cre√≠ble del 95% para la raz√≥n de tasas:  
  \( \lambda_{2019} / \lambda_{2010} \in [15.948,\ 24.852] \)



### Conclusi√≥n final

Existe **evidencia contundente** de que la tasa de delitos en Bogot√° ha aumentado de manera sostenida entre 2010 y 2019, 
seg√∫n el modelo Poisson ajustado mediante inferencia bayesiana.  

Tanto la pendiente positiva (\( \beta > 0 \)) como la raz√≥n de tasas significativamente superior a 1 (m√°s de 15 veces) 
respaldan con fuerza esta **tendencia creciente**.




### 1. Pregunta para Cali

¬øLa tasa anual de delitos en Cali ha aumentado entre los a√±os 2010 y 2019?

### 2. Hip√≥tesis bayesiana

Partimos del mismo planteamiento utilizado para Bogot√°, empleando una regresi√≥n log-lineal sobre los conteos anuales. Suponemos que el n√∫mero de delitos en Cali en el a√±o \( t \), denotado por \( Y_{\text{Cali},t} \), sigue una distribuci√≥n Poisson con par√°metro \( \lambda_{\text{Cali},t} \):

$$
Y_{\text{Cali},t} \sim \operatorname{Poisson}(\lambda_{\text{Cali},t})
$$

La tasa esperada var√≠a en el tiempo de forma log-lineal:

$$
\log \lambda_{\text{Cali},t}
= \alpha_{\text{Cali}} + \beta_{\text{Cali}} \cdot (t - 2010)
$$



### Formulaci√≥n de hip√≥tesis

- **Hip√≥tesis nula \( (H_0)\) :**  
  No hay evidencia de que la tasa de delitos en Cali haya aumentado:  
  \[
  \beta_{\text{Cali}} \le 0
  \quad \Longleftrightarrow \quad
  \lambda_{\text{Cali},2019} \le \lambda_{\text{Cali},2010}
  \]

- **Hip√≥tesis alternativa \( (H_1) \) :**  
  La tasa de delitos en Cali ha aumentado entre 2010 y 2019:  
  \[
  \beta_{\text{Cali}} > 0
  \quad \Longleftrightarrow \quad
  \lambda_{\text{Cali},2019} > \lambda_{\text{Cali},2010}
  \]



Desde la perspectiva bayesiana, se evaluar√° esta afirmaci√≥n estimando directamente la probabilidad posterior:

$$
P(\beta_{\text{Cali}} > 0 \mid \text{datos})
$$

y analizando la evoluci√≥n de las tasas simuladas \( \lambda_t \) en el periodo.
```{r}
cali_path <- "/home/fabian/Documentos/bayesiana_R/cali_datos_limpios.csv"
# Carga el dataset
delitos_cali <- read.csv(cali_path, header = TRUE, sep = ",", encoding = "UTF-8")
# Contenido basico
str(delitos_cali)
```
  
```{r}
## ---------------------------------------------------------------
##  SEGUNDO MODELO CON MUESTRA (Poisson‚Äëregresi√≥n con Œ≤)
## ---------------------------------------------------------------
set.seed(123)         # reproducibilidad
n_m <- 400            # tama√±o de la muestra (puedes variar)

# --- Muestra aleatoria ---------------------------------------
muestra3 <- delitos_cali[sample(nrow(delitos_cali), n_m), ]

# --- Limpieza de categor√≠a vac√≠a -----------------------------
muestra3 <- muestra3 %>%
  mutate(year = year(as.Date(FECHA_HECHO)))
```
**Objetivo**

Queremos obtener \( y_t \), el n√∫mero total de delitos registrados en **Cali**, dentro de la muestra, para cada a√±o \( t \in \{2010, \ldots, 2019\} \).  
Estos conteos actuar√°n como la **estad√≠stica suficiente** para ajustar el modelo de regresi√≥n Poisson con tendencia temporal.

**Notaci√≥n**

Dado que cada fila del conjunto de datos representa un delito individual, simplemente contamos el n√∫mero de observaciones por a√±o:

$$
y_t = \text{n√∫mero de observaciones en el a√±o } t
\qquad \text{(en la muestra)}
$$

```{r}
# --- Conteos por a√±o en la muestra ---------------------------
cali_yr_m <- muestra3 %>%
  group_by(year) %>%
  summarise(y = n(), .groups = "drop")  # usamos n() en vez de sum(CANTIDAD)

print(cali_yr_m)
```
### Paso 4: Verosimilitud ‚Äì Poisson

#### Modelo estad√≠stico

Suponemos que el n√∫mero de delitos registrados por a√±o en **Cali** sigue una distribuci√≥n Poisson, apropiada para modelar conteos 
de eventos discretos en unidades fijas de tiempo.

Sea \( y_t \) el n√∫mero de delitos observados en el a√±o \( t \). Entonces modelamos:

$$
y_t \mid \lambda_t \sim \operatorname{Poisson}(\lambda_t)
$$

donde \( \lambda_t \) representa la tasa esperada de delitos en el a√±o \( t \).  
Para capturar una posible tendencia temporal, utilizamos un modelo de regresi√≥n log-lineal:

$$
\log \lambda_t = \alpha + \beta \cdot (t - 2010)
$$

De este modo, el modelo permite que la tasa de delitos var√≠e de forma exponencial a lo largo del tiempo, dependiendo del valor de la pendiente \( \beta \):

- Si \( \beta > 0 \), se interpreta como una **tendencia creciente** en los delitos.
- Si \( \beta < 0 \), se interpreta como una **tendencia decreciente**.

Este tipo de modelamiento es cl√°sico en el an√°lisis de datos de conteo con estructura temporal, y est√° ampliamente recomendado en 
*Bayesian Data Analysis* (Gelman et al., 2013, cap. 14), donde se destaca que los modelos Poisson con enlace logar√≠tmico permiten 
realizar inferencias claras y coherentes sobre tasas esperadas.


```{r}
# === Paso 4: Ajuste del modelo Poisson con tendencia temporal ===
#   y_t ~ Poisson(exp(alpha + beta * (year - 2010)))

prior_list_cali <- c(
  prior(normal(0, 10), class = Intercept),   # Œ±
  prior(normal(0, 10), class = b)            # Œ≤
)

cali_brms <- brm(
  formula = y ~ 1 + I(year - 2010),
  family  = poisson(link = "log"),
  data    = cali_yr_m,
  prior   = prior_list_cali,
  chains  = 4, iter = 4000, seed = 123,
  refresh = 0
)

```
### Paso 5: Inferencia posterior ‚Äì Tendencia temporal en la tasa de delitos en Cali

Una vez ajustado el modelo de regresi√≥n Poisson mediante inferencia bayesiana con `brms`, se procede a interpretar los par√°metros posteriores, en particular la pendiente \( \beta \), que indica si existe evidencia de un cambio sistem√°tico en la tasa de delitos a lo largo del tiempo.

---

### Interpretaci√≥n bayesiana de \( \beta \)

- Si \( \beta > 0 \), sugiere que la tasa de delitos ha **aumentado** con los a√±os.
- Si \( \beta < 0 \), sugiere una **disminuci√≥n** en la tasa.
- El valor esperado \( \mathbb{E}[\beta \mid \text{datos}] \) proporciona un estimador puntual, pero m√°s relevante desde la perspectiva 
bayesiana es la **probabilidad posterior**:

  $$
  P(\beta > 0 \mid \text{datos})
  $$

Esta probabilidad se estima directamente a partir de las simulaciones de la distribuci√≥n posterior generadas por el modelo.

Este enfoque refleja la l√≥gica propuesta por *Gelman et al.* (2013, Cap√≠tulos 1 y 2), quienes argumentan que, en lugar de aceptar o 
rechazar hip√≥tesis de forma dicot√≥mica, el an√°lisis bayesiano permite **cuantificar el grado de credibilidad** de una afirmaci√≥n directamente desde la distribuci√≥n posterior.


```{r}
# === Paso 5: Extraer muestras de la posterior ===
post_draws_cali <- as_draws_df(cali_brms)

# === Calcular la probabilidad posterior de Œ≤ > 0 ===
prob_beta_gt0_cali <- mean(post_draws_cali$b_IyearM2010 > 0)

cat("P(Œ≤ > 0 | muestra Cali) ‚âà", round(prob_beta_gt0_cali, 4), "\n")
```
####**Observaci√≥n**  
La probabilidad posterior estimada  
\[
P(\beta > 0 \mid \text{datos}) \approx 0.7555
\]  
indica que cerca del 75.55 % de la masa posterior de \(\beta\) se concentra en valores positivos.  
Esto refleja una asimetr√≠a moderada hacia una posible tendencia creciente en la tasa de delitos,  
aunque tambi√©n se observa una fracci√≥n no despreciable de probabilidad asignada a valores  
negativos o cercanos a cero. Esta distribuci√≥n posterior de \(\beta\), obtenida mediante simulaciones  
MCMC, proporciona una representaci√≥n m√°s matizada y continua del conocimiento actualizado,  
en concordancia con la interpretaci√≥n propuesta por Gelman *et al.* (2013).

### Paso 6: Comparaci√≥n de tasas esperadas \( \lambda_{2010} \) vs. \( \lambda_{2019} \)

#### Fundamento

En el modelo de regresi√≥n Poisson con enlace logar√≠tmico, la tasa esperada de delitos en el a√±o \( t \) est√° dada por:

$$
\lambda_t = \exp\bigl(\alpha + \beta \cdot (t - 2010)\bigr)
$$

De esta forma, para los a√±os clave:

- \( \lambda_{2010} = \exp(\alpha) \)
- \( \lambda_{2019} = \exp(\alpha + 9 \cdot \beta) \)

A partir de las muestras posteriores obtenidas mediante MCMC, se simulan ambos valores para cada iteraci√≥n, y se procede a:

1. **Estimar la probabilidad posterior** de que la tasa haya aumentado:

   $$
   P(\lambda_{2019} > \lambda_{2010}) \approx \frac{1}{S} \sum_{s=1}^S \mathbb{I}\bigl(\lambda_{2019}^{(s)} > \lambda_{2010}^{(s)}\bigr)
   $$

2. **Calcular un intervalo cre√≠ble del 95%** para el cociente:

   $$
   \frac{\lambda_{2019}}{\lambda_{2010}}
   $$

Esto proporciona una **medida relativa del cambio** en la tasa de delitos durante el periodo analizado.

> Este enfoque es coherente con las recomendaciones de *Gelman et al.* (2013, Cap.‚ÄØ3.4), donde se enfatiza que al trabajar con modelos jer√°rquicos o de regresi√≥n, no solo deben interpretarse los par√°metros individuales, sino tambi√©n transformaciones relevantes ‚Äîcomo diferencias, razones o probabilidades‚Äî mediante simulaciones directas desde la distribuci√≥n posterior.

```{r}
# === Paso 6: Simular tasas esperadas en 2010 y 2019 ===

# Tasa para el a√±o 2010 (Œ±)
lambda_2010_cali <- exp(post_draws_cali$b_Intercept)

# Tasa para el a√±o 2019 (Œ± + 9Œ≤)
lambda_2019_cali <- exp(post_draws_cali$b_Intercept +
                        post_draws_cali$b_IyearM2010 * 9)

# Comparaci√≥n directa de probabilidades
prob_lambda_gt_cali <- mean(lambda_2019_cali > lambda_2010_cali)

# Intervalo cre√≠ble del 95 % para el cociente
ratio_cali <- lambda_2019_cali / lambda_2010_cali
ratio_ic_cali <- quantile(ratio_cali, probs = c(0.025, 0.5, 0.975))

# Resultados
cat("P(Œª_2019 > Œª_2010) en Cali ‚âà", round(prob_lambda_gt_cali, 4), "\n",
    "IC95% del cociente Œª_2019 / Œª_2010 en Cali:",
    paste(round(ratio_ic_cali, 3), collapse = " ‚Äì "), "\n")


```
#### Observaci√≥n

La probabilidad posterior estimada de que la tasa esperada de delitos en Cali haya sido mayor en 2019 que en 2010 es aproximadamente 0.7555. El intervalo cre√≠ble del 95% para el cociente \( \lambda_{2019} / \lambda_{2010} \) se encuentra entre 0.818 y 1.510, lo cual indica una considerable dispersi√≥n en la magnitud posible del cambio. Estos resultados reflejan una inclinaci√≥n moderada hacia una posible tendencia creciente, aunque tambi√©n sugieren una incertidumbre significativa en la estimaci√≥n de las tasas extremas del periodo.

### Paso 7: Visualizaci√≥n ‚Äì evoluci√≥n de la tasa \( \lambda_t \) en Cali

#### Objetivo

Representar gr√°ficamente, para cada a√±o \( t \in \{2010, \dots, 2019\} \):

- La **media posterior** de la tasa esperada \( \lambda_t = \mathbb{E}[Y_t] \)
- Un **intervalo cre√≠ble del 95%** asociado, a partir de las muestras posteriores de \( \alpha \) y \( \beta \)

Este gr√°fico permite observar la **tendencia temporal** en la tasa de delitos en Cali, e interpretar visualmente si ha habido un aumento sostenido, una disminuci√≥n o estabilidad en el tiempo.

> Este procedimiento refleja los principios descritos por *Gelman et al.* (2013, Cap.6.2), donde se enfatiza la importancia 
de **visualizar cantidades inferidas** (posteriores), no solo para comunicar resultados, sino tambi√©n para detectar patrones, tendencias o anomal√≠as.


```{r}
# === Paso 7: Visualizaci√≥n de Œª_t en Cali ===

# Secuencia de a√±os presentes en la muestra
years_cali <- sort(unique(cali_yr_m$year))  # cali_yr_m ya contiene los conteos por a√±o

# Calcular Œª_t = exp(Œ± + Œ≤*(t - 2010)) para cada a√±o y cada muestra
lambda_mat_cali <- sapply(years_cali, function(t) {
  exp(post_draws_cali$b_Intercept + post_draws_cali$b_IyearM2010 * (t - 2010))
})

# Crear resumen con media y percentiles por a√±o
lambda_df_cali <- data.frame(
  year = years_cali,
  mean = apply(lambda_mat_cali, 2, mean),
  q025 = apply(lambda_mat_cali, 2, quantile, probs = 0.025),
  q975 = apply(lambda_mat_cali, 2, quantile, probs = 0.975)
)

# Gr√°fico
ggplot(lambda_df_cali, aes(x = year, y = mean)) +
  geom_ribbon(aes(ymin = q025, ymax = q975), fill = "orange", alpha = 0.3) +
  geom_line(color = "darkorange", size = 1.2) +
  geom_point(size = 2) +
  labs(
    title = "Evoluci√≥n de la tasa esperada de delitos en Cali",
    subtitle = "Media posterior e intervalo cre√≠ble del 95%",
    x = "A√±o", y = expression(lambda[t])
  ) +
  theme_minimal(base_size = 13)


```
#### Observaci√≥n

La visualizaci√≥n de la tasa esperada \( \lambda_t \) muestra una trayectoria suavemente ascendente entre 2010 y 2019. Si bien la media posterior crece de forma gradual, los intervalos cre√≠bles del 95% son relativamente amplios y sim√©tricos, lo que indica una **incertidumbre sustancial** sobre la tasa verdadera en cada a√±o, especialmente hacia los extremos del periodo. Esta representaci√≥n gr√°fica es consistente con la probabilidad posterior estimada de crecimiento y refuerza la necesidad de considerar tanto la tendencia central como la variabilidad asociada en los an√°lisis de conteo con estructura temporal.

```{r}
# ----------------------------------------------------------
# 0. Datos
# ----------------------------------------------------------
years <- cali_yr_m$year
y     <- cali_yr_m$y
stopifnot(length(years) == length(y))

# ----------------------------------------------------------
# 1. Priors d√©biles
# ----------------------------------------------------------
prior_sd <- 10          # œÉ para Œ± y Œ≤

# ----------------------------------------------------------
# 2. Log‚Äëposterior
# ----------------------------------------------------------
log_post <- function(a, b) {
  lambda <- exp(a + b * (years - 2010))
  sum(dpois(y, lambda, log = TRUE)) +
    dnorm(a, 0, prior_sd, log = TRUE) +
    dnorm(b, 0, prior_sd, log = TRUE)
}

# ----------------------------------------------------------
# 3. Metropolis‚Äëwithin‚ÄëGibbs sampler
# ----------------------------------------------------------
set.seed(123)
S   <- 15000           # iteraciones totales
burn <- 3000           # descartadas

alpha <- beta <- numeric(S)
alpha[1] <- 0
beta[1]  <- 0
sd_prop_alpha <- 0.35  # varianzas propuestas (ligeramente mayores que Bogot√°)
sd_prop_beta  <- 0.07

for (s in 2:S) {

  # --- Œ±
  a_prop <- rnorm(1, alpha[s-1], sd_prop_alpha)
  log_r  <- log_post(a_prop, beta[s-1]) - log_post(alpha[s-1], beta[s-1])
  alpha[s] <- if (log(runif(1)) < log_r) a_prop else alpha[s-1]

  # --- Œ≤
  b_prop <- rnorm(1, beta[s-1], sd_prop_beta)
  log_r  <- log_post(alpha[s], b_prop) - log_post(alpha[s], beta[s-1])
  beta[s] <- if (log(runif(1)) < log_r) b_prop else beta[s-1]
}

# ----------------------------------------------------------
# 4. Posterior resumida
# ----------------------------------------------------------
alpha_post <- alpha[-(1:burn)]
beta_post  <- beta[-(1:burn)]

cat("Media Œ±:",  mean(alpha_post), "\n")
cat("Media Œ≤:",  mean(beta_post),  "\n")
cat("P(Œ≤>0)  :", mean(beta_post > 0), "\n")

# ---- tasas 2010 y 2019
lambda_2010 <- exp(alpha_post)
lambda_2019 <- exp(alpha_post + beta_post * 9)

cat("P(Œª_2019 > Œª_2010):",
    mean(lambda_2019 > lambda_2010), "\n")

cat("IC95% Œª_2019 / Œª_2010:",
    quantile(lambda_2019 / lambda_2010, c(.025, .975)), "\n")

# ----------------------------------------------------------
# 5. Gr√°fica de convergencia para Œ≤
# ----------------------------------------------------------
par(mfrow = c(1,2))
plot(beta_post, type = "l", col = "blue",
     main = expression("Trace de "*beta),
     ylab = expression(beta), xlab = "Iteraci√≥n")
acf(beta_post, main = expression("ACF de "*beta))

```


## 3. Comparaci√≥n: Bogot√° vs. Cali

### 1. Pregunta concreta

> ¬øHa aumentado m√°s la tasa anual de delitos en Bogot√° que en Cali durante el per√≠odo 2010‚Äì2019?

Este an√°lisis busca comparar **directamente las pendientes** de crecimiento de la tasa de delitos en ambas ciudades.  
Cada ciudad fue modelada por separado mediante una **regresi√≥n Poisson bayesiana con enlace logar√≠tmico**:

$$
\log \lambda_t^{(c)} = \alpha^{(c)} + \beta^{(c)} \cdot (t - 2010)
$$

donde \( c \in \{\text{Bogot√°}, \text{Cali}\} \), y \( \beta^{(c)} \) representa el **cambio promedio anual** en la tasa de delitos.

El objetivo es evaluar la siguiente relaci√≥n entre pendientes:

$$
\beta^{\text{Bogot√°}} > \beta^{\text{Cali}}
$$

Para ello, se comparan directamente las distribuciones posteriores obtenidas mediante MCMC con `brms`.

---

### 2. Hip√≥tesis bayesianas

- **Hip√≥tesis nula  \((H_0) \):**  
  No hay evidencia suficiente de que la tasa de delitos crezca m√°s r√°pido en Bogot√° que en Cali:
  $$
  \beta^{\text{Bogot√°}} \le \beta^{\text{Cali}}
  $$

- **Hip√≥tesis alternativa  \((H_1) \):**  
  La tasa de delitos en Bogot√° ha crecido m√°s r√°pidamente:
  $$
  \beta^{\text{Bogot√°}} > \beta^{\text{Cali}}
  $$

Desde el enfoque bayesiano, la decisi√≥n se basar√° en calcular la **probabilidad posterior**:

$$
P(\beta^{\text{Bogot√°}} > \beta^{\text{Cali}} \mid \text{datos})
$$

Este enfoque evita la necesidad de construir un modelo conjunto o recurrir a pruebas tradicionales, como lo destacan **McElreath (2020)** y **Gelman et al. (2013)**.

---

### 3. Inferencia bayesiana comparativa

Dado que ya contamos con las muestras MCMC de las pendientes \( \beta^{\text{Bogot√°}} \) y \( \beta^{\text{Cali}} \), el an√°lisis se basa en la **diferencia de pendientes**:

$$
\Delta = \beta^{\text{Bogot√°}} - \beta^{\text{Cali}}
$$

El procedimiento es el siguiente:

1. **Restar las muestras emparejadas** de cada ciudad:  
   Para cada iteraci√≥n \( s \in \{1, \dots, S\} \):

   $$
   \Delta^{(s)} = \beta^{\text{Bogot√°},(s)} - \beta^{\text{Cali},(s)}
   $$

2. **Estimar la probabilidad posterior** de diferencia positiva:

   $$
   P(\Delta > 0) \approx \frac{1}{S} \sum_{s=1}^S \mathbb{I}(\Delta^{(s)} > 0)
   $$

3. **Obtener el intervalo cre√≠ble del 95% para \( \Delta \)**:

   $$
   \text{IC}_{95\%}(\Delta) = \left[ Q_{2.5\%},\; Q_{97.5\%} \right]
   $$

Este procedimiento sigue las recomendaciones de *Gelman et al.* (2013, Cap.3), quienes proponen utilizar directamente las 
simulaciones posteriores para comparar efectos sin depender de supuestos normalizadores o valores-*p* cl√°sicos.

```{r}
# Aseg√∫rate de que estos modelos ya est√©n definidos:
# - bogo_brms: modelo ajustado para Bogot√°
# - cali_brms: modelo ajustado para Cali

# Convertir las muestras MCMC a data frames
post_draws_bogota <- as_draws_df(bogo_brms)
post_draws_cali   <- as_draws_df(cali_brms)

# Inspeccionar nombres para verificar las pendientes
names(post_draws_bogota)
names(post_draws_cali)
```


```{r}
# === Paso 3: Comparaci√≥n de pendientes beta (Bogot√° vs Cali) ===

# Aseg√∫rate de tener los objetos post_draws_bogota y post_draws_cali disponibles

# Extraer pendientes de cada ciudad
beta_bog <- post_draws_bogota$b_IyearM2010
beta_cali <- post_draws_cali$b_IyearM2010

# Asegurar igual longitud de muestras (por si acaso)
S <- min(length(beta_bog), length(beta_cali))
beta_bog <- beta_bog[1:S]
beta_cali <- beta_cali[1:S]

# Calcular diferencia de pendientes
delta <- beta_bog - beta_cali

# Probabilidad posterior de que Bogot√° tenga mayor crecimiento
prob_delta_gt0 <- mean(delta > 0)

# Intervalo cre√≠ble del 95% para Œî = Œ≤_bog - Œ≤_cali
IC_delta <- quantile(delta, probs = c(0.025, 0.5, 0.975))

# Mostrar resultados
cat("P(Œ≤_Bogot√° > Œ≤_Cali) ‚âà", round(prob_delta_gt0, 4), "\n",
    "IC95% para Œî = Œ≤_Bog - Œ≤_Cali:", paste(round(IC_delta, 4), collapse = " ‚Äì "), "\n")
```


## Conclusi√≥n comparativa: Bogot√° vs.Cali (2010‚Äì2019)

La inferencia bayesiana indica con **probabilidad posterior ‚âà1.00** que la pendiente de crecimiento anual de la tasa de delitos es **mayor en Bogot√°** que en Cali:

- \(P(\beta^{\text{Bogot√°}} > \beta^{\text{Cali}} \mid \text{datos}) \approx 1.000\)
- Intervalo cre√≠ble 95% de la diferencia \(\Delta = \beta^{\text{Bogot√°}}-\beta^{\text{Cali}}\): \([0.28,\;0.36]\)

**Interpretaci√≥n**  
- **Bogot√°:** crecimiento sostenido y pronunciado (\(\lambda_{2019}/\lambda_{2010}\) ‚âà20).  
- **Cali:** aumento leve (\(\lambda_{2019}/\lambda_{2010}\) ‚âà1.1).

**Conclusi√≥n:** La tasa esperada de delitos se ha incrementado mucho m√°s r√°pido en Bogot√° que en Cali durante 2010‚Äë2019, sugiriendo la necesidad de pol√≠ticas de seguridad diferenciadas entre ambas ciudades.
